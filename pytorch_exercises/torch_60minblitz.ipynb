{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2839b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn \n",
    "import torchvision.models as models \n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor,Lambda, Compose\n",
    "from torchvision.io import read_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51e5a7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "veri_ham  :  [[1, 2], [3, 4]]\n",
      "veri_tensor  :  tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "veri_numpy  :  [[1 2]\n",
      " [3 4]]\n",
      "veri_numpy_tensor  :  tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "oneslike_tensor  :  tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "zeroslike_tensor  :  tensor([[0, 0],\n",
      "        [0, 0]])\n",
      "veri_tensor_shape  :  torch.Size([2, 2])\n",
      "veri_tensor_dtype  :  torch.int64\n",
      "rand_tensor  :  tensor([[0.8402, 0.6322],\n",
      "        [0.3992, 0.3779]])\n",
      "ones_tensor  :  tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "zeros_tensor  :  tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1,2],[3,4]] # veri belirlenir\n",
    "x_data = torch.tensor(data) # torch için tensor oluşturur.\n",
    "\n",
    "np_data = np.array(data) # numpy array'e doldur \n",
    "x_data_from_numpy = torch.from_numpy(np_data) # numpy array'den tensor oluştur.\n",
    "\n",
    "x_ones = torch.ones_like(x_data) # x_data tensorünün boyutlarında sadece 1 lerden oluşan tensor oluştur.\n",
    "x_zeros = torch.zeros_like(x_data) #  '' ' ' ' ' ' ' sadece 0 lardan oluşan tensor oluştur.\n",
    "\n",
    "data_shape = x_data.shape \n",
    "data_type = x_data.dtype\n",
    "\n",
    "rand_tensor = torch.rand(data_shape) # random degerleri içeren data_shape boyutunda tensor oluştur.\n",
    "ones_tensor = torch.ones(data_shape) # 1 içeren ' ' ' ' ' '...\n",
    "zeros_tensor = torch.zeros(data_shape) # 0 içeren ' ' ' ' ' '...\n",
    "\n",
    "bilgiler = {'veri_ham':data,\n",
    "            'veri_tensor':x_data,\n",
    "             'veri_numpy':np_data,\n",
    "           'veri_numpy_tensor':x_data_from_numpy,\n",
    "           'oneslike_tensor':x_ones,\n",
    "           'zeroslike_tensor':x_zeros,\n",
    "           'veri_tensor_shape':data_shape,\n",
    "           'veri_tensor_dtype':data_type,\n",
    "           'rand_tensor':rand_tensor,\n",
    "           'ones_tensor':ones_tensor,\n",
    "           'zeros_tensor':zeros_tensor}\n",
    "\n",
    "for isim,icerik in bilgiler.items():\n",
    "    print(isim,\" : \",icerik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9348a8ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "110032a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor device is  cpu \n",
      " tensor([[0.9630, 0.1911, 0.4291, 0.5236],\n",
      "        [0.0327, 0.9426, 0.2166, 0.2959],\n",
      "        [0.8944, 0.2775, 0.4851, 0.2570]])\n",
      "Cuda is available\n",
      "tensor([[0.9630, 0.1911, 0.4291, 0.5236],\n",
      "        [0.0327, 0.9426, 0.2166, 0.2959],\n",
      "        [0.8944, 0.2775, 0.4851, 0.2570]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "print(\"Tensor device is \",tensor.device,\"\\n\",tensor)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda is available\")\n",
    "    tensor = tensor.to('cuda')\n",
    "    print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c88ed7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones_like(tensor)\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a2ee13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 2 : \n",
      " tensor([[1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.]], device='cuda:0')\n",
      "\n",
      "------------\n",
      "Multiplication 1 \n",
      " tensor([[1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.]], device='cuda:0') \n",
      "------------\n",
      "Multipilication 2 \n",
      " tensor([[1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1.]], device='cuda:0')\n",
      "Shape: torch.Size([3, 8])\n",
      "Mul1 ::\n",
      " tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]], device='cuda:0')\n",
      "Mul2 ::\n",
      " tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]], device='cuda:0')\n",
      "Mul3 ::\n",
      " tensor([[3., 0., 3., 3., 3., 0., 3., 3.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [3., 0., 3., 3., 3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3., 3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3., 3., 0., 3., 3.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [3., 0., 3., 3., 3., 0., 3., 3.],\n",
      "        [3., 0., 3., 3., 3., 0., 3., 3.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.cat([tensor,tensor],dim = 1 ) # concatenate, 1 vertical.\n",
    "print(\"Tensor 2 : \\n\",tensor)\n",
    "\n",
    "mul1 = tensor.mul(tensor)\n",
    "mul2 = tensor * tensor \n",
    "\n",
    "print(\"\\n------------\\nMultiplication 1 \\n\",mul1,\"\\n------------\\nMultipilication 2 \\n\",mul2)\n",
    "\n",
    "print(\"Shape:\",tensor.shape) \n",
    "matrixMul1 = tensor.matmul(tensor.T) # Matris çarpımı esnasında çarpım yapılabilmesi için sutun satıra eşit olmalıdır. Klasik lineer cebir.\n",
    "matrixMul2 = tensor @ tensor.T # Bu yüzden matrislerden birisi transpozu alınır. (Birinci ya da ikinci olmasında ki fark ?) (W.T * X + b )\n",
    "matrixMul3 = tensor.T @ tensor \n",
    "\n",
    "for i,v in zip(['Mul1','Mul2','Mul3'],[matrixMul1,matrixMul2,matrixMul3]):\n",
    "    print(i,\"::\\n\",v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93add004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5., 6., 6., 6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6., 6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6., 6., 5., 6., 6.]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.add_(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd5d054",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e27dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(root=\"data\",train=True,download=True,transform = ToTensor())\n",
    "test_data = datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dde9b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2acedfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([40963])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(len(training_data),size=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a196e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40900"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = torch.randint(len(training_data),size=(1,)).item()\n",
    "sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac3d87c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img , label = training_data[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aaba2645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape :  torch.Size([1, 28, 28])\n",
      "label :  0\n"
     ]
    }
   ],
   "source": [
    "print(\"image shape : \",img.shape)\n",
    "print(\"label : \",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98c8fdb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5880edd30>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(labels_map[label])\n",
    "plt.imshow(img.squeeze(),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ee2ac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataLoader = DataLoader(training_data, batch_size=64,shuffle = True)\n",
    "test_dataLoader = DataLoader(test_data,batch_size=64,shuffle =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8d49d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70aae1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_features[0].squeeze() # Squeeze: (A x 1 x B x C x 1 x D) -> (A x B x C x D) : Tam olarak ne yapıyor ? \n",
    "label = train_labels[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dad1a442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Sandal')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img,cmap='gray')\n",
    "plt.title(labels_map[label.item()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1731e2ee",
   "metadata": {},
   "source": [
    "# Build NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8dde4e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Active device:\",device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc6062f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class \n",
    "# Her NeuralNetwork class'ı __init__ ve forward methoduna sahiptir.\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(nn.Linear(28*28,512), \n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(512,512),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(512,10),\n",
    "                                               nn.ReLU())\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e32e0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device) # Modelimizi mevcut 'device' üzerinde çalışmasını sağlar. Amacımız device'ı GPU olarak aktif edip, GPU'ya taşımak.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50190c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1,28,28,device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e579cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([9], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4e764670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdbac104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0a3e769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features = 28*28, out_features = 20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d18f194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[-0.1767,  0.0974,  0.3826, -0.0351, -0.2551,  0.4645, -0.1716,  0.1104,\n",
      "          0.7048,  0.2467,  0.1085,  0.4576, -0.3028,  0.3171,  0.1312, -0.2769,\n",
      "         -0.0429,  0.4436,  0.4297,  0.4059],\n",
      "        [-0.1310,  0.1481,  0.2280, -0.0519, -0.1927,  0.4920, -0.4127, -0.1624,\n",
      "          0.5016,  0.1353,  0.2371,  0.2194,  0.2305,  0.4117,  0.2129, -0.0438,\n",
      "          0.0896,  0.4087,  0.5998,  0.4100],\n",
      "        [ 0.1286,  0.0478,  0.1637, -0.0016, -0.1248,  0.0046, -0.1557, -0.0072,\n",
      "          0.5256,  0.3617,  0.1472,  0.1687, -0.5080,  0.2277,  0.1199, -0.4173,\n",
      "          0.0941,  0.8228,  0.4453,  0.2408]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "After ReLU:tensor([[0.0000, 0.0974, 0.3826, 0.0000, 0.0000, 0.4645, 0.0000, 0.1104, 0.7048,\n",
      "         0.2467, 0.1085, 0.4576, 0.0000, 0.3171, 0.1312, 0.0000, 0.0000, 0.4436,\n",
      "         0.4297, 0.4059],\n",
      "        [0.0000, 0.1481, 0.2280, 0.0000, 0.0000, 0.4920, 0.0000, 0.0000, 0.5016,\n",
      "         0.1353, 0.2371, 0.2194, 0.2305, 0.4117, 0.2129, 0.0000, 0.0896, 0.4087,\n",
      "         0.5998, 0.4100],\n",
      "        [0.1286, 0.0478, 0.1637, 0.0000, 0.0000, 0.0046, 0.0000, 0.0000, 0.5256,\n",
      "         0.3617, 0.1472, 0.1687, 0.0000, 0.2277, 0.1199, 0.0000, 0.0941, 0.8228,\n",
      "         0.4453, 0.2408]], grad_fn=<ReluBackward0>) \n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU:{hidden1} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee3f92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(flatten,\n",
    "                           layer1,\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(20,10)\n",
    "                           )\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9080be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc94c553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: tensor([[-0.0027, -0.0281, -0.0029,  ..., -0.0301, -0.0037, -0.0041],\n",
      "        [ 0.0149, -0.0314,  0.0241,  ...,  0.0300,  0.0169,  0.0302]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: tensor([-0.0044, -0.0171], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: tensor([[-0.0186, -0.0372,  0.0027,  ..., -0.0187, -0.0045,  0.0306],\n",
      "        [-0.0046,  0.0170,  0.0091,  ..., -0.0190, -0.0038,  0.0001]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: tensor([-0.0108, -0.0282], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: tensor([[-0.0326,  0.0354, -0.0138,  ..., -0.0119,  0.0035, -0.0213],\n",
      "        [ 0.0111,  0.0105,  0.0113,  ..., -0.0395,  0.0072,  0.0441]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: tensor([ 0.0050, -0.0262], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Structure: \",model,\"\\n\\n\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values: {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15f1d8",
   "metadata": {},
   "source": [
    "# Backprop and Autograd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef84c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5) # input tensor\n",
    "y = torch.zeros(3) # expected output\n",
    "\n",
    "w = torch.randn(5,3, requires_grad = True)\n",
    "b = torch.randn(3, requires_grad = True)\n",
    "z = x @ w + b # X ile W nun yeri önemli.\n",
    "\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c0db570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights\n",
      " tensor([[ 0.9383,  0.0567, -0.0661],\n",
      "        [ 1.3195,  0.9560,  0.6294],\n",
      "        [ 1.0051, -0.0220,  1.7303],\n",
      "        [-0.5259,  0.2078, -0.9661],\n",
      "        [ 0.1154, -0.7371, -0.0954]], requires_grad=True)\n",
      "\n",
      "bias\n",
      " tensor([-0.5009,  1.8373, -0.4601], requires_grad=True)\n",
      "\n",
      "Z\n",
      " tensor([2.3514, 2.2986, 0.7720], grad_fn=<AddBackward0>)\n",
      "Gradient function for z =  <AddBackward0 object at 0x000001E5AE6DF820>\n",
      "Gradient function for loss =  <BinaryCrossEntropyWithLogitsBackward object at 0x000001E588960D60>\n"
     ]
    }
   ],
   "source": [
    "print('Weights\\n',w)\n",
    "print(\"\\nbias\\n\",b)\n",
    "print(\"\\nZ\\n\",z)\n",
    "print(\"Gradient function for z = \",z.grad_fn)\n",
    "print(\"Gradient function for loss = \",loss.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "81b6a4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3043, 0.3029, 0.2280],\n",
      "        [0.3043, 0.3029, 0.2280],\n",
      "        [0.3043, 0.3029, 0.2280],\n",
      "        [0.3043, 0.3029, 0.2280],\n",
      "        [0.3043, 0.3029, 0.2280]])\n",
      "tensor([0.3043, 0.3029, 0.2280])\n"
     ]
    }
   ],
   "source": [
    "loss.backward() # loss hesaplar\n",
    "print(w.grad) # Gradient değerleri w - lr * w_grad şeklinde güncelleme yapmamız\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56258045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ab5b4afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n",
      "\n",
      "Second call\n",
      " tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.],\n",
      "        [4., 4., 4., 4., 8.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      " tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.],\n",
      "        [2., 2., 2., 2., 4.]])\n"
     ]
    }
   ],
   "source": [
    "inp = torch.eye(5, requires_grad=True)\n",
    "out = (inp+1).pow(2)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"First call\\n\", inp.grad)\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nSecond call\\n\", inp.grad)\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(inp), retain_graph=True)\n",
    "print(\"\\nCall after zeroing gradients\\n\", inp.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b0c34",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "770d7628",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c5403673",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3 # öğrenme oranı\n",
    "batch_size = 64 \n",
    "epochs = 3 # Optimizasyon döngüsü sayısı \n",
    "loss_fn = nn.CrossEntropyLoss() # loss function \n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate ) # optimizasyon algoritması "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cafa0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader,model,loss_fn,optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # compute pred  and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        \n",
    "        #backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0 :\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Train loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "            \n",
    "def test_loop(dataloader,model,loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss,correct=0,0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred,y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error : \\n Test Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4300eb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      " ---------------------------------\n",
      "Train loss: 2.308573 [    0/60000]\n",
      "Train loss: 2.288735 [ 6400/60000]\n",
      "Train loss: 2.277491 [12800/60000]\n",
      "Train loss: 2.276008 [19200/60000]\n",
      "Train loss: 2.253292 [25600/60000]\n",
      "Train loss: 2.253844 [32000/60000]\n",
      "Train loss: 2.250835 [38400/60000]\n",
      "Train loss: 2.223993 [44800/60000]\n",
      "Train loss: 2.207472 [51200/60000]\n",
      "Train loss: 2.209946 [57600/60000]\n",
      "Test Error : \n",
      " Test Accuracy: 47.6%, Avg loss: 0.034549 \n",
      "\n",
      "Epoch 2 \n",
      " ---------------------------------\n",
      "Train loss: 2.220832 [    0/60000]\n",
      "Train loss: 2.149021 [ 6400/60000]\n",
      "Train loss: 2.147206 [12800/60000]\n",
      "Train loss: 2.128823 [19200/60000]\n",
      "Train loss: 2.128282 [25600/60000]\n",
      "Train loss: 2.149498 [32000/60000]\n",
      "Train loss: 2.088455 [38400/60000]\n",
      "Train loss: 2.049463 [44800/60000]\n",
      "Train loss: 2.101392 [51200/60000]\n",
      "Train loss: 2.067056 [57600/60000]\n",
      "Test Error : \n",
      " Test Accuracy: 52.4%, Avg loss: 0.032157 \n",
      "\n",
      "Epoch 3 \n",
      " ---------------------------------\n",
      "Train loss: 2.039340 [    0/60000]\n",
      "Train loss: 2.058889 [ 6400/60000]\n",
      "Train loss: 2.001116 [12800/60000]\n",
      "Train loss: 1.945333 [19200/60000]\n",
      "Train loss: 1.946584 [25600/60000]\n",
      "Train loss: 1.889613 [32000/60000]\n",
      "Train loss: 1.836469 [38400/60000]\n",
      "Train loss: 1.899712 [44800/60000]\n",
      "Train loss: 1.878453 [51200/60000]\n",
      "Train loss: 1.789866 [57600/60000]\n",
      "Test Error : \n",
      " Test Accuracy: 53.2%, Avg loss: 0.028731 \n",
      "\n",
      "...\n",
      "...\n",
      "...\n",
      " *** DONE! ***\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1} \\n ---------------------------------\")\n",
    "    train_loop(train_dataLoader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataLoader, model, loss_fn)\n",
    "print(\"...\\n...\\n...\\n *** DONE! ***\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "354c7ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model_quick.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model_quick.pth\")\n",
    "print(\"Saved PyTorch Model State to model_quick.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "46817b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quick = NeuralNetwork().to(device)\n",
    "model_quick.load_state_dict(torch.load(\"model_quick.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee578447",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35abbb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quick.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bad32d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "x, y = test_data[0][0], test_data[0][1]\n",
    "x = x.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model_quick(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
